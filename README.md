# LLM-Enhanced Recommendation System Framework for GRE Research Project

## Introduction

This project is an LLM-enhanced movie recommendation system that combines traditional recommendation algorithms like SVD with the power of Large Language Models (LLMs) to provide personalized and context-aware movie suggestions.
Our work is part of a GRE research project at the University of North Florida by myself and Dr. Ayan Dutta.

## Key Features

1. **Scalable Architecture**: The recommendation system is designed to handle large-scale datasets and can efficiently process millions of movies and user interactions, ensuring a smooth and responsive user experience.

2. **User Preference Input**: Users provide their movie preferences by rating a set of movies they love. This information is used to understand their tastes and serve as input for the SVD algorithm. Additionally users will describe what they are looking for in movies, and this will be compared to descriptions of the top N \* 10^M recommendations of the traditional algorithm to find even more tailored matches.

3. **Traditional Recommendation Algorithms**: At the core of our system, we utilize proven recommendation algorithms like SVD to generate initial movie recommendations based on user ratings and preferences.

4. **IMDb Integration**: Our system seamlessly integrates with the IMDb database to retrieve rich movie information, including descriptions, plots, and reviews. This additional context is used by the LLMs to generate more accurate similarity scores and provide comprehensive movie details to users.

5. **LLM-Enhanced Fuzzy Matching**: To improve the accuracy of movie identification, we employ LLMs to perform fuzzy matching of movie titles. This allows our system to handle variations in user input and find the closest matches even when exact titles are not provided.

6. **LLM-Powered Similarity Scoring**: We take the recommendation process a step further by using LLMs to generate similarity scores between user preferences summaries and movie descriptions. This enables us to better match user interests with relevant movies, enhancing the personalization of recommendations.

7. **Personalized Recommendations**: By combining the strengths of traditional recommendation algorithms like SVD with the advanced capabilities of LLMs, our system generates highly personalized movie recommendations tailored to each user's unique tastes and preferences.

## How It Works

1. **Data Preparation**: The system begins by loading the MovieLens dataset, which contains user ratings, movie information, and links to IMDb. It establishes mappings between MovieLens movie IDs, IMDb IDs, and movie titles to facilitate seamless data integration. The user can choose between the 32M size dataset and the 100k size dataset, depending on their computational resources and desired dataset size.

2. **User Preference Input**: Users provide their movie preferences by rating a set of movies they love. This information is used to understand their tastes and serve as input for both the SVD algorithm.

3. **Traditional Recommendation Algorithm**: We employ the SVD algorithm to generate initial movie recommendations based on user ratings and preferences. SVD identifies latent factors that capture the underlying patterns in user-movie interactions, allowing for effective recommendation generation.

4. **Movie Description Retrieval**: For each movie in the N \* 10 recommendations generated by the SVD algorithm, the system retrieves the corresponding movie descriptions from the IMDb database using the Cinemagoer API. If an exact match is not found, LLMs are employed for fuzzy matching to find the closest match, ensuring comprehensive movie information is available. If a description can't be found, then the system will generate one with an LLM that comes close in quality to one that has been handwritten.

5. **LLM-Enhanced Similarity Scoring**: The system uses LLMs to generate similarity scores between a user's preferences summary (either manually inputed by the user or generated by an LLM based off that user's top ten or less rated movies) and each movie description in the top N \* 10 recommendations given by SVD. It constructs prompts for the LLM using few-shot examples to guide the model in generating accurate similarity scores. These scores are used to refine and personalize the recommendations generated by the SVD algorithm.

6. **Recommendation Generation**: By combining the recommendations from the SVD algorithm with the similarity scores generated by the LLMs, the system identifies the top N movies that align with the user's preferences. These movies are then presented as personalized recommendations to the user.

7. **API Integration**: The recommendation system is designed to work with a locally running LLM model that exposes an OpenAI-compatible API. This allows seamless integration and communication between the recommendation system and the LLM model, enabling efficient processing of movie descriptions and similarity scoring. That being said, the system can be easily made to work with OpenAI's API if the program is run in production mode and you've set up your API key.

## Future Goals

Our research has identified several areas for future improvement and expansion of the LLM-Enhanced Movie Recommendation System:

1. **Incorporating Additional Context in User Preference Summaries**: We plan to enhance user preference summaries by including more detailed information such as favorite movies, genres, and main cast members. This additional context will help improve the accuracy of similarity scoring between user preferences and movie descriptions.

2. **Expanding Movie Descriptions**: We aim to enrich movie descriptions by incorporating factors such as IMDb's popularity ranks and main cast members. This will address user feedback about unfamiliar movies and actors in recommendations, thereby increasing user confidence in the system's suggestions.

3. **Utilizing Popularity and Cast Similarity**: By instructing the LLM to consider popularity ranks and similar casts as factors in similarity scoring, we can better align recommendations with user interests and preferences.

4. **Optimizing for Smaller, Efficient Models**: Our goal is to make the framework efficient by using smaller, cost-effective models that can run locally. This will reduce dependency on external APIs, minimize internet traffic, and maintain speed and affordability.

5. **Enhancing Framework Independence**: Given the high dependency on LLMs, we aim to optimize the framework to handle multiple users efficiently without excessive API calls. This involves refining the framework to work seamlessly with compact models, ensuring it remains practical for large-scale deployment.

6. **Balancing Traditional and LLM-Enhanced Recommendations**: While the framework enhances traditional algorithms, it is not intended to replace them entirely. Instead, it offers streaming customers a way to refine recommendations by providing specific tastes and interests, thereby improving the prediction results of existing algorithms.

These goals are designed to improve the system's performance, user satisfaction, and scalability, ensuring it remains a valuable tool for personalized movie recommendations.

## Modes of Operation

The recommendation system can be run in three different modes, each serving a specific purpose:

1. **Development Mode**:

   - **Purpose**: Used for development and testing with a locally running LLM model.
   - **Setup**: Ensure you have a local LLM model running that exposes an OpenAPI-compatible API on port 5001.
   - **Command**: Run the system using:

     ```bash
     python llm_recommendation_system.py --mode development
     ```

2. **Production Mode**:

   - **Purpose**: Utilizes OpenAI's GPT-4o mini model for generating descriptions and similarity scores, suitable for production environments.
   - **Setup**: Requires an OpenAI API key, which should be added to a `.env` file in the project root directory.
   - **Command**: Run the system using:
     ```bash python
     llm_recommendation_system.py --mode production
     ```

3. **Generate Data Mode**:
   - **Purpose**: Retrieves movie descriptions and generates user preferences for all movies and users in the dataset. This mode is used to populate the `descriptions.csv` and `preferences.csv` files in the `ml-32m` or the `ml-latest-small` directory (depending on the dataset you're generating for) for faster processing in other modes. You will be asked which dataset to generate for when you start the program.
   - **Subcommands**:
     - `--start-movie-id <int>`: Specifies the starting movie ID for data generation. Default is 1.
     - `--start-user-id <int>`: Specifies the starting user ID for data generation. Default is 1.
   - **Command**: Run the system using:
     ```bash
     python llm_recommendation_system.py --mode generate-data --start-movie-id 1 --start-user-id 1
     ```

## Getting Started

To get started with the LLM-Enhanced Movie Recommendation System, follow these steps:

1. Clone the repository:

```bash
git clone https://github.com/Windz-GameDev/Recommendation-Systems-Research cd Recommendation-Systems-Research
```

2. Install the required Python packages:

```bash
pip install -r requirements.txt
```

3.  Set up the local LLM model:

    - Ensure that you have a locally running LLM model that exposes an OpenAPI-compatible API on port 5001.
    - The LLM model should be accessible at `http://localhost:5001/v1/chat/completions`.
    - An example application for running local LLMs that meets both of the above criteria is [KoboldCPP](https://github.com/LostRuins/koboldcpp), which allows you to run language models on your local machine.

4.  Prepare the dataset:

    - The recommendation system supports both the MovieLens 32M size dataset and the MovieLens latest 100k size dataset. Choose the appropriate dataset based on your computational resources and desired dataset size.
    - The MovieLens datasets are not included in the repository due to their large size. You need to download them manually:
      - a. Create a `Datasets` folder in the root of your project if it doesn't exist already.
      - b. Inside the `Datasets` folder, create a `Movie_Lens_Datasets` folder.
      - c. Download the MovieLens dataset of your choice:
        - For the 32M dataset: Go to https://grouplens.org/datasets/movielens/32m/ and download "ml-32m.zip"
        - For the 100k katest dataset: Go to https://grouplens.org/datasets/movielens/latest/ and download "ml-latest-small.zip"
      - d. Extract the folder from within the zip file, open it, and then drag its contents into the correct dataset folder:
        - For 32M dataset: `Datasets/Movie_Lens_Datasets/ml-32m/`
        - For 100k latest dataset: `Datasets/Movie_Lens_Datasets/ml-latest-small/`
    - Ensure that the dataset files (`ratings.csv`, `movies.csv`, `links.csv`) are present in the extracted folder.
    - The project uses the [Phi-3-mini-4k-instruct-gguf](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf) model from Hugging Face for the LLM. This model is designed to provide high-quality language understanding and generation capabilities.
    - The `descriptions.csv` files are included in the repository and will be automatically downloaded when you clone the project. This file contains cached movie descriptions to speed up the recommendation process.

5.  Create a `.env` file in the project root directory and add your OpenAI API key:

```plaintext
OPENAI_API_KEY=your_api_key_here
```

6.  Run the recommendation system (uses development mode by default):

```bash
python llm_recommendation_system.py
```

7. Follow the prompts to provide your movie preferences and receive personalized recommendations.

## Contributing

We welcome contributions from the open-source community to make this project even better. If you have any ideas, suggestions, or bug reports, please open an issue or submit a pull request on our GitHub repository.

## License

This project is licensed under the [MIT License](LICENSE).
