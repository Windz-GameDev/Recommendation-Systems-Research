AutoRec: Autoencoders Meet Collaborative Filtering

Suvash Sedhain*, Aditya Krishna Menon‘, Scott Sanner‘*, Lexing Xie*'
¥ NICTA, * Australian National University
suvash.sedhain@anu.edu.au, { aditya.menon, scott.sanner }@nicta.com.au,
lexing.xie@anu.edu.au

ABSTRACT

This paper proposes AutoRec, a novel autoencoder frame-
work for collaborative filtering (CF). Empirically, AutoRec’s
compact and efficiently trainable model outperforms state-
of-the-art CF techniques (biased matrix factorization, RBM-
CF and LLORMA) on the Movielens and Netflix datasets.

Categories and Subject Descriptors D.2.8 [Informa-
tion Storage and Retrieval|Information Filtering

Keywords Recommender Systems; Collaborative Filtering;
Autoencoders

1. INTRODUCTION

Collaborative filtering (CF) models aim to exploit infor-
mation about users’ preferences for items (e.g. star ratings)
to provide personalised recommendations. Owing to the
Netflix challenge, a panoply of different CF models have
been proposed, with popular choices being matrix factori-
sation [1, 2] and neighbourhood models [5]. This paper
proposes AutoRec, a new CF model based on the autoen-
coder paradigm; our interest in this paradigm stems from
the recent successes of (deep) neural network models for vi-
sion and speech tasks. We argue that AutoRec has represen-
tational and computational advantages over existing neural
approaches to CF [4], and demonstrate empirically that it
outperforms the current state-of-the-art methods.

2. THE AUTOREC MODEL

In rating-based collaborative filtering, we have m users,
n items, and a partially observed user-item rating matrix
ReR™*". Each user u € U = {1...m} can be represented
by a partially observed vector ry) = (Rais comEtun) ER,
Similarly, each item i € J = {1...n} can be represented
by a partially observed vector r“ = (Ru,...Rmi) € R™.
Our aim in this work is to design an item-based (user-based)
autoencoder which can take as input each partially observed
r® (re), project it into a low-dimensional latent (hidden)
space, and then reconstruct r (r™) in the output space
to predict missing ratings for purposes of recommendation.

Formally, given a set S of vectors in R*, and some k € Ni,
an autoencoder solves

min Y 7 |r — h(x; 4)|L3, (1)

res

Copyright is held by the author/owner(s).

WWW 2015 Companion, May 18-22, 2015, Florence, Italy.
ACM 978-1-4503-3473-0/15/05.
http://dx.doi.org/10.1145/2740908.2742726 .

rO=(Ri Ra Rai Rimi)

   

Figure 1: Item-based AutoRec model. We use plate notation
to indicate that there are n copies of the neural network (one
for each item), where W and V are tied across all copies.

 

where h(r;4) is the reconstruction of input r € R*,
h(r; 0) = f (We g(Vr +m) +b)

for activation functions f(-),g(-). Here, 0 = {W, V, 1, b}
for transformations W € R?**,V € R**¢, and biases pu €
R‘,b € R®. This objective corresponds to an auto-associative
neural network with a single, k-dimensional hidden layer.
The parameters @ are learned using backpropagation.

The item-based AutoRec model, shown in Figure 1, ap-
plies an autoencoder as per Equation 1 to the set of vectors
{r }i1, with two important changes. First, we account for
the fact that each r“ is partially observed by only updating
during backpropagation those weights that are associated
with observed inputs, as is common in matrix factorisation
and RBM approaches. Second, we regularise the learned pa-
rameters so as to prevent overfitting on the observed ratings.
Formally, the objective function for the Item-based AutoRec
(I-AutoRec) model is, for regularisation strength \ > 0,

)> (2)

 

 

Boa y BN
. @ _ @, Boy ey 2 Vv
m2 lle AE; 8))llo + 5° (WI le + II

where || - ||2, means that we only consider the contribution
of observed ratings. User-based AutoRec (U-AutoRec) is
derived by working with {r“}"™,. In total, LAutoRec re-
quires the estimation of 2mk + m+ k parameters. Given
learned parameters 6, I-AutoRec’s predicted rating for user
u and item 7 is

Rui = (hr; ))u.- (3)

Figure 1 illustrates the model, with shaded nodes corre-
sponding to observed ratings, and solid connections corre-

sponding to weights that are updated for the input r,
 

 

 

ML-IM _ML-10M FO gC) RMSE = “a oe sox
U-RBM 0.881 0.823 Identity Identity 0.872 eee a ee ;
; pony ; I-RBM 0.854 0.825 -
I-RBM 0.854 0.825 Sigmoid Identity 0.852 .
: eee ganwaat U-RBM 0.881 0.823 0.845
U-AutoRec 0.874 0.867 Identity Sigmoid 0.831 oe
T-AutoRec _0.881__0.782 Sigmoid Sigmoid _ 0.836 TEORM® 0833 orre2 0S
- - - LAutoRec 0.831 0.782 0.823
(a) (b)

Cd)

Table 1: (a) Comparison of the RMSE of I/U-AutoRec and RBM models. (b) RMSE for I-AutoRec with choices of linear and
nonlinear activation functions, Movielens 1M dataset. (c) Comparison of I-AutoRec with baselines on MovieLens and Netflix
datasets. We remark that IL-RBM did not converge after one week of training. LLORMA’s performance is taken from [2].

AutoRec is distinct to existing CF approaches. Com-
pared to the RBM-based CF model (RBM-CF) [4], there
are several differences. First, RBM-CF proposes a gener-
ative, probabilistic model based on restricted Boltzmann
machines, while AutoRec is a discriminative model based
on autoencoders. Second, RBM-CF estimates parameters
by maximising log likelihood, while AutoRec directly min-
imises RMSE, the canonical performance in rating predic-
tion tasks. Third, training RBM-CF requires the use of con-
trastive divergence, whereas training AutoRec requires the
comparatively faster gradient-based backpropagation. Fi-
nally, RBM-CF is only applicable for discrete ratings, and
estimates a separate set of parameters for each rating value.
For r possible ratings, this implies nkr or (mkr) parame-
ters for user- (item-) based RBM. AutoRec is agnostic to r
and hence requires fewer parameters. Fewer parameters en-
ables AutoRec to have less memory footprint and less prone
to overfitting. Compared to matrix factorisation (MF) ap-
proaches, which embed both users and items into a shared
latent space, the item-based AutoRec model only embeds
items into latent space. Further, while MF learns a linear
latent representation, AutoRec can learn a nonlinear latent
representation through activation function g(-).

3. EXPERIMENTAL EVALUATION

In this section, we evaluate and compare AutoRec with
RBM-CF [4], Biased Matrix Factorisation [1] (BiasedMF),
and Local Low-Rank Matrix Factorisation (LLORMA) [2]
on the Movielens 1M, 10M and Netflix datasets. Follow-
ing [2], we use a default rating of 3 for test users or items
without training observations. We split the data into ran-
dom 90%-10% train-test sets, and hold out 10% of the train-
ing set for hyperparamater tuning. We repeat this splitting
procedure 5 times and report average RMSE. 95% confi-
dence intervals on RMSE were +0.003 or less in each experi-
ment. For all baselines, we tuned the regularisation strength
d € {0.001, 0.01, 0.1, 1, 100, 1000} and the appropriate latent
dimension k € {10, 20, 40, 80, 100, 200, 300, 400, 500}.

A challenge training autoencoders is non-convexity of the
objective. We found resilient propagation (RProp) [3] to
give comparable performance to L-BFGS, while being much
faster. Thus, we use RProp for all subsequent experiments:
Which is better, item- or user-based autoencoding
with RBMs or AutoRec? Table 1a shows item-based (I-)
methods for RBM and AutoRec generally perform better;
this is likely since the average number of ratings per item is
much more than those per user; high variance in the number
of user ratings leads to less reliable prediction for user-based
methods. I-AutoRec outperforms all RBM variants.

How does AutoRec performance vary with linear
and nonlinear activation functions f(-),g(-)? Table 1b
indicates that nonlinearity in the hidden layer (via g(-)) is
critical for good performance of I-AutoRec, indicating its

 

0.87

0.86

0.85

RMSE

0.84
0.83

0.82
o 100 = 200» 300 400—~SS—«500
number of hidden units

Figure 2: RMSE of I-AutoRec on Movielens 1M as the num-
ber of hidden units k varies.

potential advantage over MF methods. Replacing sigmoids
with Rectified Linear Units (ReLU) performed worse. All
other AutoRec experiments use identity f(-) and sigmoid
g(-) functions.

How does performance of AutoRec vary with the
number of hidden units? In Figure 2, we evaluate the
performance of AutoRec model as the number of hidden
units varies. We note that performance steadily increases with
the number of hidden units, but with diminishing returns.
All other AutoRec experiments use k = 500.

How does AutoRec perform against all baselines?
Table 1c shows that AutoRec consistently outperforms all
baselines, except for comparable results with LLORMA on
Movielens 10M. Competitive performance with LLORMA is
of interest, as the latter involves weighting 50 different local
matrix factorization models, whereas AutoRec only uses a
single latent representation via a neural net autoencoder.
Do deep extensions of AutoRec help? We developed a
deep version of -AutoRec with three hidden layers of (500,
250, 500) units, each with a sigmoid activation. We used
greedy pretraining and then fine-tuned by gradient descent.
On Movielens 1M, RMSE reduces from 0.831 to 0.827 indi-
cating potential for further improvement via deep AutoRec.
Acknowledgments NICTA is funded by the Australian Gov-
ernment as represented by the Dept. of Communications and
the ARC through the ICT Centre of Excellence program. This
research was supported in part by ARC DP140102185.

References

{1] Y. Koren, R. Bell, and C. Volinsky. Matrix factorization tech-
niques for recommender systems. Computer, 42, 2009.

[2] J. Lee, S. Kim, G. Lebanon, and Y. Singer. Local low-rank
matrix approximation. In ICML, 2013.

[3] M. Riedmiller and H. Braun. A direct adaptive method for
faster backpropagation learning: the rprop algorithm. In
IEEE International Conference on Neural Networks, 1993.

[4] R. Salakhutdinov, A. Mnih, and G. Hinton. Restricted Boltz-
mann machines for collaborative filtering. In JCML, 2007.

[5] B. Sarwar, G. Karypis, J. Konstan, and J. Riedl. Item-based
collaborative filtering recommendation algorithms. In WWW,
2001.
