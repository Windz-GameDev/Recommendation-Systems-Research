--- Page 1 ---
Representation Learning with Large Language Models
for Recommendation
Xubin Ren
University of Hong Kong
xubinrencs@gmail.comWei Wei
ABSTRACT
Recommender systems have seen significant advancements with
the influence of deep learning and graph neural networks, particu-
larly in capturing complex user-item relationships. However, these
graph-based recommenders heavily depend on ID-based data, po-
tentially disregarding valuable textual information associated with
users and items, resulting in less informative learned representa-
tions. Moreover, the utilization of implicit feedback data introduces
potential noise and bias, posing challenges for the effectiveness of
user preference learning. While the integration of large language
models (LLMs) into traditional ID-based recommenders has gained
attention, challenges such as scalability issues, limitations in text-
only reliance, and prompt input constraints need to be addressed
for effective implementation in practical recommender systems. To
address these challenges, we propose a model-agnostic framework
RLMRec that aims to enhance existing recommenders with LLM-
empowered representation learning. It proposes a recommendation
paradigm that integrates representation learning with LLMs to cap-
ture intricate semantic aspects of user behaviors and preferences.
RLMRec incorporates auxiliary textual signals, employs LLMs for
user/item profiling, and aligns the semantic space of LLMs with
collaborative relational signals through cross-view alignment. This
work further demonstrates the theoretical foundation of incorpo-
rating textual signals through mutual information maximization,
which improves the quality of representations. Our evaluation inte-
grates RLMRec with state-of-the-art recommender models, while
also analyzing its efficiency and robustness to noise data. Implemen-
tation codes are available at https://github.com/HKUDS/RLMRec.
WWW â€™24, May 13â€“17, 2024, Singapore, Singapore
ACM ISBN 979-8-4007-0171-9/24/05. . . $15.00
https://doi.org/10.1145/3589334.3645458CCS CONCEPTS
â€¢Information systems â†’Recommender systems.
KEYWORDS
Large Language Models, Recommendation, Alignment
ACM Reference Format:
Xubin Ren, Wei Wei, Lianghao Xia, Lixin Su, Suqi Cheng, Junfeng Wang,
Dawei Yin, and Chao Huang. 2024. Representation Learning with Large
Language Models for Recommendation. In Proceedings of the ACM Web
Conference 2024 (WWW â€™24), May 13â€“17, 2024, Singapore, Singapore. ACM,
Singapore, Singapore, 12 pages. https://doi.org/10.1145/3589334.3645458
1 INTRODUCTION
Recommender systems have evolved to provide personalized item
recommendations based on user interactions, with deep learning
and graph neural networks playing a significant role [ 4,39]. Graph-
based recommenders like NGCF [ 35] and LightGCN [ 11] have
demonstrated impressive capabilities in capturing complex user-
item relationships, making them state-of-the-art approaches.
However, itâ€™s important to note that recent graph-based recom-
menders heavily rely on ID-corresponding information for learning.
The training data in this line only consists of mapped user/item
indices, and their interactions are represented in an interaction ma-
trix using binary values (1 for interaction and 0 for no interaction).
While this data arrangement has shown effectiveness, one limita-
tion is its primary reliance on ID-based information, potentially
overlooking other valuable data such as rich textual information
associated with users and items. The absence of this additional
information can lead to reduced informativeness in the learned
representations. Furthermore, it is worth noting that a substantial
portion of the data in these graph-based recommenders consists
of implicit feedback [ 27,33], which can introduce noise from false
negatives or bias (e.g., misclicks [ 34] or popularity bias [ 5]). Conse-
quently, the learned representations of these GNN-based models
heavily rely on the inherent quality of the data. This heavy reliance
on the data quality poses a potential challenge as it can lead to
detrimental representations that hinder the effectiveness of recom-
mendation systems, especially when the data contains noise.
In recent times, there have been several endeavors to leverage
diverse data modalities in order to enhance traditional ID-based
3464


--- Page 2 ---
WWW â€™24, May 13â€“17, 2024, Singapore, Singapore Xubin Ren et al.
30 35 40 45 50
Num. of Candidates0.060.070.080.090.10 Recall@10
LightGCN
 rerank by ChatGPT
30 35 40 45 50
Num. of Candidates0.080.100.120.14 Recall@20
30 35 40 45 50
Num. of Candidates0.050.060.070.08 NDCG@10
30 35 40 45 50
Num. of Candidates0.050.060.070.080.09 NDCG@20
Figure 1: LLMâ€™s performance for recommendation reranking
when dealing with different sizes of candidate items.
recommenders [ 9,17,46]. Particularly interesting is the emergence
of large language models (LLMs) like GPT-4 [ 24] and LLaMA [ 32],
which have demonstrated impressive capabilities in neural lan-
guage understanding tasks. This development has sparked signifi-
cant interest among researchers, who are actively exploring how
LLMs, with their proficiency in handling textual content, can extend
the capabilities of recommendation systems beyond the original
data [ 7,18,21]. A primary focus of current research in this field
revolves around aligning recommendation approaches with the
characteristics of language models through prompt design. Meth-
ods like InstructRec [ 47] structure the recommendation task in an
instruction-question-answering format, enabling LLMs to simul-
taneously address the recommendation objective and respond to
intricately designed questions [ 1,9]. However, these methods still
lag behind existing recommenders in terms of efficiency and preci-
sion. This can be attributed to inherent shortcomings associated
with this approach, including the following key aspects:
i)Scalability issues in practical recommenders. Utilizing large
language models (LLMs) in personalized user behavior modeling
requires significant computational resources. As the scale of user
behavior data grows, so do the computational demands and asso-
ciated inference time costs. For instance, in TALLRec [ 1], where
recommendations are generated based on an instruction-question-
answering format, the response time for LLaMA2-13B to provide
recommendations to individual users is approximately 3.6 seconds,
with an input size of around 800 tokens (equivalent to approxi-
mately 5 users). However, this poses significant challenges when
attempting to scale up the approach for practical recommender
systems with a substantial user base and extensive item catalog.
ii)Limitations stemming from text-only reliance. LLMs have
the potential to generate text answers that may include recommen-
dations for non-existent items due to hallucination issues [ 20]. This
poses a challenge in ensuring the accuracy and reliability of the
generated recommendations. Additionally, the limited capacity of
prompt inputs, constrained by the maximum number of tokens
(e.g., 2048 tokens for LLaMA), hinders the effective modeling of
comprehensive collaborative signals with global user dependencies.
To validate the aforementioned limitations, we evaluate the ef-
fectiveness of directly using LLMs in enhancing the re-ranking
task [ 12,31] for recommendation on the Amazon dataset. Specif-
ically, we utilize LightGCN [ 11] as the backbone model, which
retrieve a ranking list of 50 candidate items for each user. To further
refine the recommendations, we integrate the textual information
of each item with our custom prompts (for details, please refer to
Appendix A.3). These prompts are then processed by ChatGPT (i.e.,
gpt-3.5-turbo). The objective of this task is to re-rank the item list
for each user and identify the Top-10&20 most relevant items.It is evident from the results in Figure 1 that the recommen-
dations refined by the ChatGPT perform worse than the original
results provided by LightGCN. This indicates limitations when
blindly using LLMs to improve the re-ranking process in recom-
mendation. These limitations can be attributed to three factors:
i) The hallucination issue of LLMs, suggesting items not in the
candidate set; ii) The lack of a comprehensive global text-based
collaborative relationship input due to token limits; iii) Addition-
ally, it is worth noting that the reranking process using LLM takes
several hours to complete, which poses a challenge when dealing
with large-scale data in real-world recommendation scenarios. Due
to page constraints, we provide detailed analysis and examples in
the Appendix to demonstrate the phenomenon of hallucination.
Contributions. In light of the aforementioned limitations, we aim
to leverage the power of LLMs to seamlessly enhance existing
recommender systems. To accomplish this, we propose a model-
agnostic framework called RLMRec ( Representation Learning with
Large Language Models for Recommendation). The core idea of
RLMRec is to utilize representation learning as a bridge between
ID-based recommenders and LLMs. Our new recommendation par-
adigm aims to preserve the accuracy and efficiency of existing
recommenders while harnessing the powerful text comprehension
capabilities of LLMs to understand the intricate semantic aspects
of user behaviors and preferences. To begin, we lay the theoretical
groundwork by modeling the benefits of incorporating auxiliary tex-
tual signals for representation learning. This involves transforming
the textual signals into meaningful representations and establishing
a theoretical foundation for maximizing mutual information within
general recommendation models. Moreover, we develop a user/item
profiling paradigm empowered by LLMs, enhancing representation
expressiveness by incorporating comprehensive semantic under-
standing from the global knowledge space of LLMs.
Furthermore, we propose to align the semantic space of LLMs and
the representation space of collaborative relational signals through
a cross-view alignment framework. This alignment is achieved
through a cross-view mutual information maximization scheme,
which allows us to find a common semantic subspace where the
textual and collaborative relational embeddings are well aligned
from the contrastive and generative modeling, respectively. In a
nutshell, our main contributions can be summarized as follows:
â€¢This work aims to explore the potential of enhancing the recom-
mendation performance of existing recommender systems, by
leveraging LLMs and aligning their semantic space with collabo-
rative relation modeling for better representation learning.
â€¢We propose a model-agnostic representation learning framework
called RLMRec, which is guided by our theoretical findings. This
framework leverages contrastive or generative modeling tech-
niques to enhance the quality of learned representations.
â€¢We establish a theoretical foundation to demonstrate the effective-
ness of incorporating textual signals in enhancing the representa-
tion learning. By utilizing mutual information maximization, we
show how textual signals can improve the representation quality.
â€¢We integrate RLMRec with various state-of-the-art recommender
models and validate the effectiveness of our method. Additionally,
we analyze the frameworkâ€™s robustness to noise and incomplete
data, showcasing its ability to handle real-world challenges.
3465

--- Page 3 ---
Representation Learning with Large Language Models for Recommendation WWW â€™24, May 13â€“17, 2024, Singapore, Singapore
2 RELATED WORK
GNN-enhanced Collaborative Filtering. Collaborative Filter-
ing (CF), a fundamental technique in recommendation systems,
has been extensively studied [ 16,30]. An emerging direction is
to use historical user-item interactions to create a bipartite graph
and employ Graph Neural Networks (GNNs) to capture high-order
collaborative relationships. These graph-based methods, such as
NGCF [ 35], GCCF [ 6], LightGCN [ 11], have demonstrated state-
of-the-art performance, improving recommendation effectiveness.
However, the sparsity and noise in implicit feedback data pose
challenges to graph-based methods. To address this, researchers
have explored the use of self-supervised learning (SSL) techniques
as auxiliary learning objectives to enhance robustness in recom-
mendations [ 43,45]. Among various SSL techniques, contrastive
learning has emerged as a prominent solution in collaborative fil-
tering models. Methods like SGL [ 37], SimGCL [ 44], NCL [ 19],
LightGCL [ 3] leverage contrastive data augmentation to improve
recommendation performance. In this work, we take a step further
by integrating LLMs with existing CF models to effectively align the
knowledge and reasoning abilities of LLMs with the collaborative
relation learning for enhancing recommendation performance.
Large Language Models for Recommendation. leveraging LLMs
for recommendation systems has gained interest [ 7,18,21,38]. Sev-
eral studies have leveraged LLMs as inference models by designing
prompts that align them with recommendation tasks. For example,
P5 [9] converts the user interaction data into textual prompts using
item indexes, which are then used for language model training.
Chat-REC [ 8] builds a conversational recommender by transform-
ing user profiles and interactions into prompts for LLMs to generate
recommendations. InstructRec [ 47] and TALLRec [ 1] employ in-
structional designs to define recommendation tasks and fine-tune
LLMs to align with these instructions for generating recommen-
dations. However, using LLMs directly for recommendation tasks
faces challenges like high computational costs and slow inference
times. To address this, our approach adopts mutual information
maximization to align LLMs knowledge with collaborative relation
modeling, enabling scalable and effective recommendations.
3 METHODOLOGY
3.1 Theoretical Basis of RLMRec
Collaborative Filtering. In our recommendation scenario, we
have a set of users U=ð‘¢1,...,ð‘¢ð¼and a set of itemsV=ð‘£1,...,ð‘£ð½.
The observed user-item interactions are represented by X. In learning-
based recommenders, each user and item is assigned initial embed-
dings xð‘¢andxð‘£. The goal is to learn user and item representations
eð‘¢,eð‘£through a recommender model (i.e., eð‘¢,eð‘£=R(xð‘¢,xð‘£)) that
maximizes the posterior distribution shown below:
ð‘(e|X)âˆð‘(X|e)ð‘(e). (1)
In practical recommendation scenarios, the observed user-item
interactionsXoften contain noise, including false positives ( e.g.,
misclicks or interactions influenced by popularity bias) and false
negatives (e.g., users do not interact with unseen but interested
items). As a result, the learned representation ecan also be affected
by this noise, which negatively impacts recommendation accuracy.
In this work, we introduce a hidden prior belief zthat is inherently
z
e sð‘ð‘
noise noise
Learning Mechanismshared 
information
for rec.e snoisenoisy signals in e are alleviated
e-CF-side rational representation
s â€“LLMs -enhanced semantic representation
z-hidden prior benefit for recommendationAlignmentFigure 2: The type of directed graph model under consid-
eration. As the alignment between CF-side representation
and LLM-enhanced representation, the noisy effects in the
learned representations ð‘’are alleviated in RLMRec.
beneficial for recommendation. This prior belief helps identify the
true positive samples in X. Hence, the generation of representation
einvolves a combination of the advantageous prior belief zand the
unavoidable noise present during the learning process.
Text-enhanced User Preference Learning. To mitigate the im-
pact of irrelevant signals on the representation, it is necessary to
incorporate auxiliary informative cues. One approach is to intro-
duce textual information, e.g., user and item profiles, which provide
insights for user preference learning. These profiles can be encoded
using language models to generate representations sâˆˆRð‘‘ð‘ that
effectively capture the semantic aspects of user preferences. Impor-
tantly, both sandecapture shared information that is relevant to
the aspects associated with user-item interactions. This shared in-
formation is crucial as it indicates the inclusion of beneficial aspects
for recommendation, aligning with the prior belief z.
With the collaborative-side representation eand textual-side
representation s, both of which contain recommendation-beneficial
information generated from z, our objective is to learn the optimal
value of edenoted as eâˆ—, by maximizing the conditional probability:
eâˆ—=arg max
eEð‘(e,s)[ð‘(z,s|e)]. (2)
The underlying intuition behind maximizing the conditional
probability is to ensure that the learnable representation efrom
recommender models incorporates purer information generated
from the prior belief zand the shared information with the semantic
representation s. By doing so, the relevance and benefits of the
learned representations efor recommendation are enhanced.
Theorem 1. Maximizing the posteriori probability Eð‘(e,s)[ð‘(z,s|e)]
given the hidden prior belief z, is equivalent to maximizing the mutual
information ð¼(ð‘’;ð‘ )between the CF-side relational representation e
and LLM-side semantic representation s.
Proof. It is important to note that since the profiles of users and
items are fixed, the probability ð‘(s)remains constant during the
learning process. Therefore, we can deduce the following:
Eð‘(e,s)[ð‘(z,s|e)]âˆ Eð‘(e,s)log[âˆ«
zð‘(z,s|e)
ð‘(s)ð‘‘z] (3)
=Eð‘(e,s)log[âˆ«
zð‘(z,e|s)ð‘‘z
ð‘(e)] (4)
=Eð‘(e,s)log[ð‘(e|s)
ð‘(e)]=ð¼(e,s). (5)
3466

--- Page 4 ---
WWW â€™24, May 13â€“17, 2024, Singapore, Singapore Xubin Ren et al.
Item Profile Generation
User Profile Generation
LLMs
title: Ice Cream
description: â€¦.----------------------------
user feedback: â€¦.
It attracts â€¦.
reasoning: â€¦.
interacted items:[ title: â€¦ 
profile: â€¦
review: â€¦ ]
LLMs
The user likes â€¦
reasoning: â€¦.
Semantic Representation
Recommender Model
Collaborative Data
Bidirectional AlignmentSemanticCollaborative Data
Unidirectional ReconstructionSemantic
LLMs
LLMs
(a) Profile Generation via Reasoning (b) Contrastive Alignment (c) Generative AlignmentRecommender Model
Figure 3: The overall framework of our proposed LLM-enhanced representation learning framework RLMRec.
Letâ€™s consider eandsas data samples, assuming that we have
ð‘pairwise corresponding elements of eands, forming the sets
E={e1,..., eð‘–,..., eð‘}andS={s1,..., sð‘–,..., sð‘}, respectively.
Based on this, we optimize the mutual information as follows.
Theorem 2. By introducing the density ratio to preserve mutal
information [ 23]ð‘“(s,e)âˆð‘(s|e)/ð‘(s), the maximization of ð¼(eð‘–;sð‘–)
can be reformulated as maximizing the following lower bound:
Elog[ð‘“(sð‘–,eð‘–)Ã
sð‘—âˆˆSð‘“(sð‘—,eð‘–)]. (6)
Proof. Based on the property of mutual information, we have
ð¼(eð‘–,sð‘–)=ð¼(sð‘–,eð‘–). With this in mind, we make the deductions as:
ð¼(sð‘–,eð‘–)â‰¥ð¼(sð‘–,eð‘–)âˆ’log(ð‘)=âˆ’Elog[ð‘(sð‘–)
ð‘(si|eð‘–)ð‘] (7)
â‰¥âˆ’E log[1+ð‘(sð‘–)
ð‘(si|eð‘–)(ð‘âˆ’1)] (8)
=âˆ’Elog[1+ð‘(sð‘–)
ð‘(si|eð‘–)(ð‘âˆ’1)Esð‘—âˆˆSð‘›ð‘’ð‘”ð‘(sð‘—|eð‘–)
ð‘(sð‘—)](9)
â‰ˆâˆ’E log[1+ð‘(sð‘–)
ð‘(si|eð‘–)âˆ‘ï¸
sjâˆˆSð‘›ð‘’ð‘”ð‘(sð‘—|eð‘–)
ð‘(sð‘—)] (10)
=Elog[ð‘“(sð‘–,eð‘–)Ã
sð‘—âˆˆSð‘“(sð‘—,eð‘–)]. (11)
Here, Snegrepresents the negative samples when considering the
ð‘–-th sample (i.e., Sð‘›ð‘’ð‘”=S\ð‘ ð‘–). Up to this point, we have derived,
from a theoretical perspective, how to alleivate noisy effects in
representations by introducing external knowledge. However, this
approach also presents two challenges: i) Challenge 1: How to
obtain effective descriptions of users and items that capture their
interaction preferences. ii) Challenge 2: How to involves effec-
tively modeling the density ratio ð‘“(s,e)to maximize the mutual
information between eands. In the following sections, we discuss
potential solutions to address these two challenges.
3.2 User/Item Profiling Paradigm
In our previous derivation, we emphasize the importance of obtain-
ing textual descriptions, referred to as profiles, for users and items.
These profiles play a crucial role in mitigating the impact of noise in
the learned representations of recommenders and enable a semantic
understanding of usersâ€™ and itemsâ€™ interaction preferences. Ideally,
user and item profiles should exhibit the following characteristics:
â€¢User profile: should effectively encapsulate the particular types
of items that users are inclined to favor, allowing for a comprehen-
sive representation of their personalized tastes and preferences.â€¢Item profile: It should eloquently articulate the specific types
of users that the item is apt to attract, providing a clear represen-
tation of the itemâ€™s characteristics and qualities that align with
the preferences and interests of those users.
In some cases, the original data may include textual proper-
ties related to users and items. For example, in the Yelp dataset,
users provide reviews for visited businesses, and businesses have
attributes such as location and category. However, such textual data
often contains extraneous noise, leading to common predicaments:
i)Missing Attributes: Some attributes of certain items or users
may be missing; ii) Noisy Textual Data: The text itself may be
contaminated with a plethora of noise that is irrelevant to usersâ€™
preferences. For instance, in the Steam dataset, user reviews for
games may contain numerous special symbols or irrelevant infor-
mation. These challenges make it difficult to distill useful user and
item profiles from text. As a result, prevailing models often convert
low-noise attributes into one-hot encodings without effectively
leveraging the semantic information present in the textual data.
Fortunately, recent advancements in Large Language Models
(LLMs) have unleashed their remarkable text processing capabili-
ties, enabling them to address a wide range of NLP tasks, including
text denoising and summarization. This pivotal development opens
up new possibilities for generating user and item profiles from
the noisy textual features inherent in the dataset. Leveraging the
tremendous potential of LLMs, we propose a paradigm for profile
generation that capitalizes on collaborative information. Consid-
ering that datasets often contain a higher proportion of textual
descriptions for item attributes compared to user attributes, our
approach takes an item-to-user perspective, as outlined below.
3.2.1 Profile Generation via Reasoning. Recent research has
demonstrated the effectiveness of incorporating process reasoning
in LLMs to mitigate hallucination and improve the quality of gener-
ated outputs. Building upon these findings, we have meticulously
designed the system prompt Sð‘¢/ð‘£as part of the input provided to
LLMs. The objective is to clearly define its functionality in gener-
ating user profile for user ð‘¢or item profile for item ð‘£by precisely
specifying the input-output content and desired output format.
Importantly, we explicitly emphasize the inclusion of reasoning
processes as an integral part of the generated output. By combining
this system prompt with user/item profile generation prompts Qð‘¢
andQð‘£, we can leverage LLMs to generate accurate profiles. The
specific process is outlined as follows:
Pð‘¢=ð¿ð¿ð‘€ð‘ (Sð‘¢,Qð‘¢),Pð‘£=ð¿ð¿ð‘€ð‘ (Sð‘£,Qð‘£) (12)
3467

--- Page 5 ---
Representation Learning with Large Language Models for Recommendation WWW â€™24, May 13â€“17, 2024, Singapore, Singapore
3.2.2 Item Prompt Construction. we categorize the textual in-
formation of an item ð‘£âˆˆV into four types: title ð›¼, original descrip-
tionð›½, dataset-specific attributes ðœ¸=ð›¾1,...,ð›¾|ðœ¸|, and a collection of
ð‘›reviews from users r=ð‘Ÿ1,...,ð‘Ÿð‘›. Based on these categories, we
can formally outline the arrangement of the input prompt Qð‘£for
item-profile generation as follows:
Qð‘£=ð‘“ð‘£(x)ð‘¤.ð‘Ÿ.ð‘¡. x=(
[ð›¼,ð›½], ifð›½exists,
[ð›¼,ðœ¸,Ë†râŠ‚r],other wise.(13)
In our approach, we use a function ð‘“ð‘£(Â·)specific to each item, which
combines various text features into a single string. If the original
descriptionð›½is missing, we randomly sample a subset of reviews Ë†r
and combine them with the attributes for input. By incorporating
item descriptions or user reviews, our prompts provide precise
information to Large Language Models, ensuring that the generated
item profiles accurately reflect appealing characteristics.
3.2.3 User Prompt Construction. To generate the profile of user
ð‘¢, we leverage collaborative information, assuming that we have
already generated the item profiles beforehand. Specifically, we
consider the items interacted with by user ð‘¢asIð‘¢and uniformly
sample a subset of items Ë†Ið‘¢âŠ‚Ið‘¢. For each item ð‘£inË†Ið‘¢, we concate-
nate its textual attributes as cð‘£=[ð›¼,Pð‘£,ð‘Ÿð‘£ð‘¢], whereð‘Ÿð‘£ð‘¢represents
the review provided by user ð‘¢. The input promptQð‘¢for user-profile
generation can be defined as follows:
Qð‘¢=ð‘“ð‘¢({cð‘£|ð‘£âˆˆË†Ið‘¢}). (14)
The function ð‘“ð‘¢(Â·)serves a similar purpose to ð‘“ð‘£(Â·)by organizing
the textual content into a coherent string. Each textual attribute
cð‘£includes user reviews, which authentically reflect their genuine
opinions. This construction of the user prompt provides valuable
insights into their true preferences. Due to space constraints, we
have included the detailed design of the prompt, including S,Q,
andð‘“ð‘¢/ð‘£(Â·), along with sample examples in Appendix A.2.
3.3 Density Ratio Modeling for Mutual
Information Maximization
In this section, we outline the process of modeling the density ratio,
denoted asð‘“(sð‘–,eð‘–), with the objective of maximizing the mutual
information ð¼(sð‘–,eð‘–). First of all, it is important to note that we
have previously generated user/item profiles Pð‘¢/ð‘£that showcase
their interaction preferences. As such, it is logical to encode the
semantic representation sbased on these profiles as follow:
sð‘¢=T(Pð‘¢),sð‘£=T(Pð‘£). (15)
Here,T(Â·) refers to a cutting-edge technology known as a text
embedding model [ 14,29], which has been shown to effectively
transform diverse text inputs into fixed-length vectors that retain
their inherent meaning and contextual information.
According to [ 23], the density ratio ð‘“(sð‘–,eð‘–)can be interpreted
as a positive real-valued score measurement function that captures
the similarity between sð‘–andeð‘–. A more accurate modeling of
the density ratio [ 28] can have a positive impact on the alignment
between CF-side rational representations and LLMs-enhanced se-
mantic representations, helping to mitigate the influence of noisy
signals in representation learning. In this context, we propose two
types of modeling approaches that are well-suited for achieving thisalignment. The first approach is contrastive modeling, which has
been extensively validated [ 15,37] for effectively aligning different
views bidirectionally, such as through pull and push pairs. The sec-
ond approach is mask-reconstruction generative modeling, which
is widely used as a self-supervised mechanism for reconstructing
the partially masked input from data itself [ 10,13]. By employing
CF-side representations to reconstruct the semantic representations,
we can effectively align these two forms of information.
3.3.1 Contrastive Alignment. As depicted in Fig 3 (b), we denote
the specific implementation of ð‘“(sð‘–,eð‘–)as contrastive alignment.
ð‘“(sð‘–,eð‘–)=ð‘’ð‘¥ð‘(ð‘ ð‘–ð‘š(ðœŽâ†“(sð‘–),eð‘–)). (16)
The function ð‘ ð‘–ð‘š(Â·)represents the cosine similarity, while ðœŽâ†“de-
notes a multi-layer perception that maps the semantic representa-
tionsð‘–into the feature space of eð‘–. In our contrastive alignment,
we treat eð‘–andsð‘–as positive sample pairs. During the learning
process, these pairs are pulled towards each other to align their
representations. In the specific implementation, the objective is to
bring positive sample pairs closer within a batch while considering
the remaining samples as negatives.
3.3.2 Generative Alignment. Taking inspiration from recent
research on the masked autoencoder (MAE), which is considered
a paradigm of generative self-supervised learning, we propose an
additional modeling approach for the density ratio within the MAE.
ð‘“(sð‘–,eð‘–)=ð‘’ð‘¥ð‘(ð‘ ð‘–ð‘š(sð‘–,ðœŽâ†‘(Ë†eð‘¢)))ð‘¤.ð‘Ÿ.ð‘¡. Ë†eð‘–=R({x}\xð‘–).(17)
We employ ðœŽâ†‘as a multi-layer perception model to map the repre-
sentations to the semantic feature space. x\xð‘–represents the initial
embedding of the ð‘–-th sample with masking applied. The generative
process follows a single-direction reconstruction approach, focus-
ing on reconstructing the semantic representations exclusively for
the masked samples. Specifically, the masking operation involves
replacing the initial embedding with a designated mask token (i.e.,
[ð‘€ð´ð‘†ð¾]), and a random subset of users/items is masked and subse-
quently reconstructed. This allows us to explore the reconstruction
capabilities within the semantic feature space.
With our contrastive and generative alignment method, we ef-
fectively align the knowledge of the LLM with the domain of under-
standing user preferences. This is achieved by combining id-based
collaborative relational signals with text-based behavior semantics.
We have given the names RLMRec-Con andRLMRec-Gen to
our two proposed modeling approaches, respectively. In our ex-
periments conducted on real-world data, we will comprehensively
evaluate the performance of these two models across various tasks,
each showcasing its unique advantages and disadvantages.
3.4 Model-agnostic Learning
Up until this point, our focus has been on optimizing the CF-side
relational representation eand LLM-side semantic representation s.
Any model that can perform representation learning for users/items
can undergo the optimization process described earlier. Hence, our
approach is model-agnostic and can seamlessly enhance existing
collaborative filtering recommenders. Assuming that the optimiza-
tion objective of the recommender Ris denoted asLR, our overall
3468

--- Page 6 ---
WWW â€™24, May 13â€“17, 2024, Singapore, Singapore Xubin Ren et al.
optimization function Lcan be formulated as follows:
L=LR+Lð‘–ð‘›ð‘“ð‘œð‘¤.ð‘Ÿ.ð‘¡.Lð‘–ð‘›ð‘“ð‘œ=âˆ’Elog[ð‘“(sð‘–,eð‘–)Ã
sð‘—âˆˆSð‘“(sð‘—,eð‘–)],(18)
Minimizing the overall optimization function Lcorresponds to
maximizing the mutual information mentioned earlier.
4 EVALUATION
This section presents the experimental evaluation of our RLMRec
on multiple datasets to address the following research questions:
â€¢RQ1: Does our proposed RLMRec improve upon existing state-
of-the-art recommenders across various experimental settings?
â€¢RQ2: Do the LLM-enhanced semantic representations contribute
to the recommendation performance improvement?
â€¢RQ3: Does our proposed framework effectively tackle the issue
of noisy data through cross-view semantic alignment?
â€¢RQ4: What is the potential of our model as a pre-training frame-
work for enhancing the performance of recommender systems?
â€¢RQ5: How does our RLMRec perform w.r.t training efficiency?
4.1 Experimental Settings
4.1.1 Datasets. We conduct evaluations of our RLMRec on three
public datasets: Amazon-book: This dataset contains user ratings
and corresponding reviews for books sold on Amazon. Yelp: This
dataset is a user-business dataset that provides extensive textual
category information about various businesses. Steam: This dataset
consists of textual feedback given by users for electronic games
available on the Steam platform. Following the similar settings
in [35,42,44] for data preprocessing, we filter out interactions
with ratings below 3 for both the Amazon-book and Yelp data. No
filtering is applied to the Steam dataset due to the absence of rating
scores. We then perform k-core filtering and divided each dataset
into training, validation, and testing sets using a 3:1:1 ratio. Please
refer to Table 5 in Appendix for a summary of the dataset statistics.
4.1.2 Evaluation Protocols and Metrics. To ensure compre-
hensive evaluation and mitigate bias, we adopt the all-rank pro-
tocol [ 11,36,37] across all items to accurately assess our recom-
mendations. We use two widely adopted ranking-based metrics:
Recall@N and NDCG@N, which measure the model effectiveness.
4.1.3 Base Models. We evaluate the effectiveness of our RLM-
Rec by integrating it with state-of-the-art representation-based
recommenders based on SSLRec [25].
â€¢GCCF [6]: It simplifies graph-based recommender design by
re-evaluating the role of non-linear operations in GNNs.
â€¢LightGCN [11]: It creates a lightweight recommender by stream-
lining redundant neural modules in graph message passing.
â€¢SGL [37]: It utilizes node/edge dropout as a data augmentator to
generate diverse perspectives for contrastive learning.
â€¢SimGCL [44]: It enhances recommendation performance by in-
troducing an augmentation-free view generation technique.
â€¢DCCF [26]: It captures intent-wise relationships for recommen-
dation purposes using disentangled contrastive learning.
â€¢AutoCF [41]: It is a self-supervised masked autoencoder to auto-
mate the process of data augmentation for recommendation.4.1.4 Implementation Details. The dimension of representa-
tions (i.e., xande) is set to 32 for all base models. We determine the
hyperparameters for each model through grid search. To generate
user and item profiles, we leverage the ChatGPT model (specifically,
gpt-3.5-turbo) provided by OpenAI. We use the text-embedding-ada-
002 [ 22] to generate semantic representations s. During training, all
methods are trained with a fixed batch size of 4096 and a learning
rate of 1e-3 using the Adam optimizer. We adopt the early stop
technique based on the modelâ€™s performance on the validation set.
4.2 Performance Comparison (RQ1)
Model-agnostic Performance Gain. To demonstrate the effec-
tiveness of RLMRec in improving recommendation performance,
we integrate it into six state-of-the-art collaborative filtering mod-
els. We conduct experiments using 5 random initializations and
report the average results in Table 1. The evaluation results reveal
several interesting observations, as outlined below:
â€¢Overall, we consistently observe that integrating RLMRec with
the backbone recommenders leads to improved performance com-
pared to the original versions. This provides compelling evidence
for the effectiveness of RLMRec. We attribute these improve-
ments to two key factors: i) RLMRec enables accurate user/item
profiling empowered by LLMs, enhancing the representation
of rich semantic information from user interaction behaviors.
ii) our cross-view mutual information maximization facilitates
the cooperative enhancement of CF-side relational embeddings
and LLM-side semantic representations, effectively filtering out
irrelevant noise in the recommendation features.
â€¢It is clear that both contrastive and generative modeling ap-
proaches generally improve performance. However, it is impor-
tant to note that the contrastive approach exhibits superior per-
formance when combined with various backbones like GCCF and
SimGCL. Conversely, when applied to AutoCF, which involves
masked reconstruction, RLMRec-Gen shows more significant
improvements. We speculate that the mask operation functions
as a form of regularization, leading to better results when used
in conjunction with methods that employ a generative approach.
Superiority over LLM-enhanced Approach. In addition, we con-
duct a comparative evaluation of the effectiveness of RLMRec in
comparison to KAR [ 40], a recent LLM-enhanced user behavior
modeling approach. KAR aims to generate textual user/item de-
scriptions to enhance the learning of user preferences for the CTR
task. To ensure a fair comparison, we utilized the same semantic
representation as in our approach and employed two classic meth-
ods (LightGCN and SGL) as the backbone models. This could be
attributed to the fact that, while KAR incorporates textual infor-
mation into the learning of user preferences, it treats the semantic
representation as input features for the model. As a result, it may
not effectively align the textual knowledge with the user behavior
representations and could be more susceptible to irrelevant noise
from either user behaviors or the LLM knowledge base.
4.3 Ablation Study (RQ2)
In this section, we examine the impact of integrating semantic rep-
resentations on performance. To do this, we shuffle the acquired
3469

--- Page 7 ---
Representation Learning with Large Language Models for Recommendation WWW â€™24, May 13â€“17, 2024, Singapore, Singapore
Table 1: Recommendation performance Imprvement of all backbone methods on different datasets in terms of Recall and
NDCG. The superscript * indicates the Imprvement is statistically significant where the p-value is less than 0.05.
Data Amazon-b
ook Y
elp Steam
Backb
one V
ariants R@5
R@10 R@20 N@5 N@10 N@20 R@5
R@10 R@20 N@5 N@10 N@20 R@5
R@10 R@20 N@5 N@10 N@20
Semantic
Embeddings Only 0.0081
0.0125 0.0199 0.0072 0.0088 0.0112 0.0013
0.0022 0.0047 0.0014 0.0018 0.0026 0.0033
0.0062 0.0120 0.0031 0.0043 0.0064
GCCFBase 0.0537
0.0872 0.1343 0.0537 0.0653 0.0807 0.0390
0.0652 0.1084 0.0451 0.0534 0.0680 0.0500
0.0826 0.1313 0.0556 0.0665 0.0830
RLMRe
c-Con 0.0561* 0.0899* 0.1395* 0.0562* 0.0679* 0.0842* 0.0409* 0.0685* 0.1144* 0.0474* 0.0562* 0.0719* 0.0538* 0.0883* 0.1398* 0.0597* 0.0713* 0.0888*
RLMRe
c-Gen 0.0551*
0.0891* 0.1372* 0.0559* 0.0675* 0.0832* 0.0393
0.0654 0.1074 0.0454 0.0535 0.0678 0.0532*
0.0874* 0.1385* 0.0588* 0.0702* 0.0875*
Best
Imprv.â†‘4.28%â†‘3.10%â†‘3.87%â†‘4.66%â†‘3.98%â†‘4.34%â†‘4.87%â†‘5.06%â†‘5.54%â†‘5.10%â†‘5.24%â†‘5.74%â†‘7.60%â†‘6.90%â†‘6.47%â†‘7.37%â†‘7.22%â†‘6.99%
LightGCNBase 0.0570
0.0915 0.1411 0.0574 0.0694 0.0856 0.0421
0.0706 0.1157 0.0491 0.0580 0.0733 0.0518
0.0852 0.1348 0.0575 0.0687 0.0855
RLMRe
c-Con 0.0608* 0.0969* 0.1483* 0.0606* 0.0734* 0.0903* 0.0445* 0.0754* 0.1230* 0.0518* 0.0614* 0.0776* 0.0548*
0.0895* 0.1421* 0.0608* 0.0724* 0.0902*
RLMRe
c-Gen 0.0596*
0.0948* 0.1446* 0.0605* 0.0724* 0.0887* 0.0435*
0.0734* 0.1209* 0.0505 0.0600* 0.0761* 0.0550* 0.0907* 0.1433*
0.0607* 0.0729* 0.0907*
Best
Imprv.â†‘6.67%â†‘5.90%â†‘5.10%â†‘5.57%â†‘5.76%â†‘5.49%â†‘5.70%â†‘6.80%â†‘6.31%â†‘5.50%â†‘5.86%â†‘5.87%â†‘6.18%â†‘6.46%â†‘6.31%â†‘5.74%â†‘6.11%â†‘6.08%
SGLBase 0.0637
0.0994 0.1473 0.0632 0.0756 0.0913 0.0432
0.0722 0.1197 0.0501 0.0592 0.0753 0.0565
0.0919 0.1444 0.0618 0.0738 0.0917
RLMRe
c-Con 0.0655* 0.1017*
0.1528* 0.0652* 0.0778* 0.0945* 0.0452*
0.0763* 0.1248* 0.0530* 0.0626* 0.0790* 0.0589* 0.0956* 0.1489* 0.0645* 0.0768* 0.0950*
RLMRe
c-Gen 0.0644
0.1015 0.1537* 0.0648* 0.0777* 0.0947* 0.0467* 0.0771* 0.1263* 0.0537* 0.0631* 0.0798* 0.0574*
0.0940* 0.1476* 0.0629* 0.0752* 0.0934*
Best
Imprv.â†‘2.83%â†‘2.31%â†‘4.34%â†‘3.16%â†‘2.91%â†‘3.72%â†‘8.10%â†‘6.79%â†‘5.51%â†‘7.19%â†‘6.59%â†‘5.98%â†‘5.20%â†‘4.03%â†‘3.12%â†‘4.37%â†‘4.07%â†‘3.60%
SimGCLBase 0.0618
0.0992 0.1512 0.0619 0.0749 0.0919 0.0467
0.0772 0.1254 0.0546 0.0638 0.0801 0.0564
0.0918 0.1436 0.0618 0.0738 0.0915
RLMRe
c-Con 0.0633* 0.1011* 0.1552* 0.0633* 0.0765* 0.0942* 0.0470
0.0784* 0.1292* 0.0546 0.0642 0.0814* 0.0582* 0.0945* 0.1482* 0.0638* 0.0760* 0.0942*
RLMRe
c-Gen 0.0617
0.0991 0.1524* 0.0622 0.0752 0.0925* 0.0464
0.0767 0.1267 0.0541 0.0634 0.0803 0.0572
0.0929 0.1456* 0.0627* 0.0747* 0.0926*
Best
Imprv.â†‘2.43%â†‘1.92%â†‘2.65%â†‘2.26%â†‘2.14%â†‘2.50%â†‘0.64%â†‘1.55%â†‘3.03%âˆ’
â†‘0.63%â†‘1.62%â†‘3.19%â†‘2.94%â†‘1.53%â†‘3.24%â†‘2.98%â†‘2.95%
DCCFBase 0.0662
0.1019 0.1517 0.0658 0.0780 0.0943 0.0468
0.0778 0.1249 0.0543 0.0640 0.0800 0.0561
0.0915 0.1437 0.0618 0.0736 0.0914
RLMRe
c-Con 0.0665
0.1040* 0.1563* 0.0668 0.0798* 0.0968* 0.0486* 0.0813* 0.1321* 0.0561* 0.0663* 0.0836* 0.0572* 0.0929* 0.1459* 0.0627* 0.0747* 0.0927*
RLMRe
c-Gen 0.0666
0.1046* 0.1559* 0.0670* 0.0801* 0.0969* 0.0475
0.0785 0.1281* 0.0549 0.0646 0.0815 0.0570*
0.0918 0.1430 0.0625 0.0741 0.0915
Best
Imprv.â†‘0.60%â†‘2.65%â†‘3.03%â†‘1.82%â†‘2.69%â†‘2.76%â†‘3.85%â†‘4.50%â†‘5.76%â†‘3.31%â†‘3.59%â†‘4.50%â†‘2.14%â†‘1.53%â†‘1.53%â†‘1.46%â†‘1.49%â†‘1.42%
A
utoCFBase 0.0689
0.1055 0.1536 0.0705 0.0828 0.0984 0.0469
0.0789 0.1280 0.0547 0.0647 0.0813 0.0519
0.0853 0.1358 0.0572 0.0684 0.0855
RLMRe
c-Con 0.0695
0.1083* 0.1586* 0.0704 0.0837 0.1001* 0.0488*
0.0814* 0.1319* 0.0562* 0.0663* 0.0835* 0.0540*
0.0876* 0.1372* 0.0593* 0.0704* 0.0872*
RLMRe
c-Gen 0.0693
0.1069* 0.1581* 0.0701 0.0830 0.0996 0.0493* 0.0828* 0.1330* 0.0572* 0.0677* 0.0848* 0.0539* 0.0888* 0.1410* 0.0593* 0.0710* 0.0886*
Best
Imprv.â†‘0.87%â†‘2.65%â†‘3.26%â†“0.14%â†‘1.87%â†‘1.73%â†‘5.12%â†‘4.94%â†‘3.91%â†‘4.57%â†‘4.64%â†‘4.31%â†‘4.05%â†‘4.10%â†‘3.83%â†‘3.67%â†‘3.80%â†‘3.63%
Table 2: Comparison with LLMs-enhanced Approaches.
Data Amazon-book Yelp
Backb. Variants R@20 N@20 R@20 N@20
Light-
GCNBase 0.1411 0.0856 0.1157 0.0733
KAR 0.1416+0.3%0.0863+0.8%0.1194+3.2%0.0756+3.1%
RLMRec-Con 0.1483+5.1%0.0903+5.5%0.1230+6.3%0.0776+5.9%
RLMRec-Gen 0.1446+2.5%0.0887+3.6%0.1209+4.5%0.0761+3.8%
SGLBase 0.1473 0.0913 0.1197 0.0753
KAR 0.1372âˆ’6.9%0.0875âˆ’4.2%0.1208+0.9%0.0761+1.1%
RLMRec-Con 0.1528+3.7%0.0945+3.5%0.1248+4.3%0.0790+4.9%
RLMRec-Gen 0.1537+4.3%0.0947+3.7%0.1263+5.5%0.0798+6.0%
LightGCN GCCF SimGCL DCCF0.120.14Recall@20LightGCN GCCF SimGCL DCCF0.070.080.09NDCG@20
/uni0000000b/uni00000044/uni0000000c/uni00000003/uni00000035/uni0000002f/uni00000030/uni00000035/uni00000048/uni00000046/uni00000010/uni00000026/uni00000052/uni00000051Shuffle Base Contriever Instructor Default
LightGCN GCCF SimGCL DCCF0.100.120.14Recall@20LightGCN GCCF SimGCL DCCF0.050.080.10NDCG@20
/uni0000000b/uni00000045/uni0000000c/uni00000003/uni00000035/uni0000002f/uni00000030/uni00000035/uni00000048/uni00000046/uni00000010/uni0000002a/uni00000048/uni00000051
Figure 4: Ablation study on variant text embedding models
conducted on the Amazon-book dataset. Shuffling involves
reordering user/item embeddings.
semantic representations, creating a misalignment with collabora-
tive relational representation and LLMâ€™s knowledge. We use the
default semantic encoding model, text-embedding-ada-002 [ 2], and
also experiment with advanced models like Contriever [ 14] and
Instructor [ 29]. We evaluate our approach on four backbone meth-
ods (i.e., LightGCN, GCCF, SimGCL, and DCCF). The results are
summarized in Figure 4, leading to two key observations.
â€¢After randomly rearranging the semantic representations to dis-
rupt the correlation between collaborative and semantic signals,
5% 10% 15% 20% 25%
Noise Ratio0.100.110.120.130.14 Recall@20
Base
RLMRec-Con
RLMRec-Gen
5% 10% 15% 20% 25%
Noise Ratio0.0650.0700.0750.0800.085 NDCG@20
Base
RLMRec-Con
RLMRec-GenFigure 5: Comparing performance on different noise ratios in
the Amazon-book dataset with LightGCN as the base model.
we observe a decrease in performance for both RLMRec-Con
and RLMRec-Gen on the evaluated backbone models. This in-
dicates that the shuffled representations introduce noise due to
the mismatch between semantic and collaborative information.
It provides evidence that accurate alignment between the LLMâ€™s
semantic knowledge and collaborative relationships among users
is crucial for enhancing recommendation performance.
â€¢When we utilize variant text embedding models like Contriever
and Instructor, our RLMRec still enhances the base performance,
similar to the default setting with text-embedding-ada-002. This
indicates that our RLMRec can effectively leverage an appropri-
ate text encoder capable of transferring textual semantics into
preference representations to improve the performance of the
recommender backbone. Moreover, the ability of text embedding
models to capture semantic information with higher accuracy
can lead to even more significant improvements.
4.4 In-depth Analysis of RLMRec (RQ3 â€“ RQ5)
4.4.1 Performance w.r.t. Noisy Data (RQ3). We assess the ro-
bustness of RLMRec to data noise by adding non-existent inter-
actions to the original training data. Noise levels range from 5%
to 25% relative to the training set size. Using the Amazon dataset,
we compare the performance of vanilla LightGCN with LightGCN
enhanced by our RLMRec-Con/Gen. Key findings from Fig 5 are:
3470

--- Page 8 ---
WWW â€™24, May 13â€“17, 2024, Singapore, Singapore Xubin Ren et al.
Table 3: Performance comparison with different initialized
parameters from various pre-training methods on the Yelp.
Metric Recall NDCG
Pretrained Params @5 @10 @20 @5 @10 @20
None 0.0274 0.0462 0.0820 0.0203 0.0270 0.0375
Base 0.0304 0.0557 0.0971 0.0229 0.0319 0.0439
RLMRec-Con 0.0359 0.0613 0.1034 0.0261 0.0352 0.0475
RLMRec-Gen 0.0362 0.0612 0.1068 0.0263 0.0353 0.0484
Table 4: RLMRecâ€™s efficiency with various recommenders.
Ama-Variants GCCF LightGCN SGL SimGCL DCCF AutoCF
Base 0.88s 1.01s 2.18s 2.62s 2.26s 2.73s
RLMRec-Con 1.95s 1.94s 2.58s 3.02s 2.49s 2.96s
RLMRec-Gen 1.72s 1.76s 2.36s 2.69s 2.29s 2.96s
Yelp-Variants GCCF LightGCN SGL SimGCL DCCF AutoCF
Base 1.11s 1.26s 2.80s 3.35s 3.02s 3.96s
RLMRec-Con 2.39s 2.57s 3.27s 3.95s 3.42s 4.41s
RLMRec-Gen 2.03s 2.12s 3.20s 3.50s 3.24s 4.39s
Steam-Variants GCCF LightGCN SGL SimGCL DCCF AutoCF
Base 2.05s 2.27s 5.42s 6.47s 9.31s 8.44s
RLMRec-Con 4.32s 4.67s 6.77s 7.88s 10.18s 10.06s
RLMRec-Gen 3.33s 3.81s 6.10s 6.89s 9.57s 9.89s
â€¢(i) Both RLMRec-Con and RLMRec-Gen consistently outperform
the LightGCN backbone model at all noise levels. This highlights
the advantages of incorporating semantic information and lever-
aging mutual information to filter out irrelevant data, resulting
in improved recommendations and robustness over noise.
â€¢(ii) RLMRec-Con has shown better resistance to data noise com-
pared to RLMRec-Gen. This is likely due to the inherent noise
introduced by the generative method through node masking. In
contrast, contrastive methods encounter less noise, leading to
superior performance under the same noise ratio.
4.4.2 Performance in Pre-training Scenarios (RQ4). We ex-
plore the potential of our semantically involved training mechanism
as a pre-training technique for downstream models. Using the Yelp
dataset, we utilize data from 2012 to 2017 for pre-training and divide
the data from 2018 to 2019 into a training set, a validation set, and
a test set (the downstream dataset). Both datasets contain the same
users and items. We train vanilla LightGCN and our model on the
pre-training dataset. The learned parameters are used to initialize
the embeddings for vanilla LightGCN, which is then trained on the
downstream dataset. Key findings from Table 3 are:
â€¢Pre-training with parameters yields superior results compared
to no pre-training, regardless of whether it was done with the
base model or our RLMRec. This suggests that the pre-training
dataset contains valuable collaborative information that helps
predict user/item preferences and benefits downstream tasks.
â€¢Both RLMRec-Con and RLMRec-Gen provide better pre-training
benefits compared to pre-training with the base model alone,
with RLMRec-Gen achieving the best results. This highlights
the advantage of incorporating semantic information and the
effectiveness of generative methods in pre-training scenarios,
potentially due to the regulatory function of the mask operation,
preventing overfitting on the pre-training dataset.
4.4.3 Analysis of Training Efficiency (RQ5). We analyze the
time complexity of using RLMRec. The theoretical time complexity
Mining Similar Preference via LLMs>3hops
The user is likely â€¦ also 
appreciate friendly service and a 
clean environment. Food enthusiasts 
seeking â€¦, a warm and inviting ambiance , and attentive service would 
also appeal to the user. â€¦
â€¦ this user is likely to enjoy 
businesses that offer a variety of options, have friendly staff, and 
provide a cozy and inviting atmosphere . â€¦
matchð‘¢ð‘¢1998
ð‘¢ð‘¢227
W/O Semantic Alignment
relevance score
0.40
rank
1245
W/ Semantic Alignment
relevance score
increase0.40 0.52
rank
increase1245 500Figure 6: Case study on capturing global user dependencies.
of the multi-layer perception ( ðœŽâ†‘andðœŽâ†“) for both RLMRec-Con
and RLMRec-Gen is O(ð‘Ã—ð‘‘ð‘ Ã—ð‘‘ð‘’). For RLMRec-Con, the loss
computation introduces an additional complexity of ð‘‚(ð‘2Ã—ð‘‘). For
RLMRec-Gen, the time complexity is ð‘‚(ð‘€Ã—ð‘‘+ð‘€Ã—ð‘Ã—ð‘‘), where
the masking operation accounts for ð‘€Ã—ð‘‘, withð‘€representing
the number of masked nodes. In Table 4, we present the epoch time
of training on a server with an Intel Xeon Silver 4314 CPU and
an NVIDIA RTX 3090 GPU. The results show that the time cost of
RLMRec-Gen is consistently lower than that of RLMRec-Con. This
is primarily because the value of ð‘in RLMRec-Con is determined
by the batch size, which tends to be larger than the number of
masked nodes M in RLMRec-Gen. Additionally, for larger models
with improved performance, the additional time complexity is only
around 10% to 20% compared to the original time.
4.5 Case Study
We explore the integration of LLM-enhanced semantics to capture
global user relationships that are not easily captured through direct
message passing. Figure 6 presents a case study where the distance
between user ð‘¢1998andð‘¢227exceeds 3 hops. To evaluate the modelsâ€™
ability to capture their relationship, we examine the similarity of
user representations. We compared LightGCN and RLMRec-Con,
both using the same backbone. Two metrics were introduced: a
relevance score for user ð‘¢1998and the ranking of its long-distance
neighbors ( >3 hops) based on the score. By incorporating semantic
information derived from LLMs, such as shared interests between
ð‘¢1998andð‘¢227(e.g., friendly service), we observed an increase in
both the relevance score and ranking. This suggests that the learned
representations from RLMRec capture global collaborative relation-
ships beyond ID-based recommendation techniques.
5 CONCLUSION
This paper presents RLMRec, a model-agnostic framework that
leverages Large Language Models (LLMs) to improve the repre-
sentation performance of recommender systems. We introduce a
collaborative profile generation paradigm and a reasoning-driven
system prompt, emphasizing the inclusion of reasoning processes
in the generated output. RLMRec utilizes contrastive and generative
alignment techniques to align CF-side relational embeddings with
LLM-side semantic representations, effectively reducing feature
noise. The framework combines the strengths of general recom-
menders and LLMs, supported by robust theoretical guarantees, and
is extensively evaluated on real-world datasets. Our future inves-
tigations will focus on advancing LLM-based reasoning results in
recommender systems by providing more insightful explanations.
3471

--- Page 10 ---
WWW â€™24, May 13â€“17, 2024, Singapore, Singapore Xubin Ren et al.
Table 5: Statistics of the experimental datasets.
Dataset #Users #Items #Interactions Density
Amazon-book 11,000 9,332 120,464 1.2 ð‘’âˆ’3
Yelp 11,091 11,010 166,620 1.4 ð‘’âˆ’3
Steam 23,310 5,237 316,190 2.6 ð‘’âˆ’3
Algorithm 1: Training Procedure in RLMRec-Con
input : Base modelR, implicit feedback X, semantic
representation sfor each user & item and learning
rateðœ‚
Result: Trained model parameters Î˜
1repeat
2 uniformly sample batch data B={(ð‘¢,ð‘£ð‘ð‘œð‘ ,ð‘£ð‘›ð‘’ð‘”)}âˆˆX ;
3 inference collaborative-side representation eð‘¢/ð‘£withR;
4 calculate model optimization objective LRbased onB;
5 calculateð¿ð‘–ð‘›ð‘“ð‘œ w.r.t. Eq (16 & 18) for all ð‘¢/ð‘£inB;
6L=LR+Lð‘–ð‘›ð‘“ð‘œ;
7 Î˜â†Î˜âˆ’ðœ‚âˆ‡Î˜L;
8until convergence ;
Algorithm 2: Training Procedure in RLMRec-Gen
input : Base modelR, implicit feedback X, semantic
representation sfor each user & item, learning rate
ðœ‚and masking ratio ð›¼
Result: Trained model parameters Î˜
1repeat
2 uniformly sample batch data B={(ð‘¢,ð‘£ð‘ð‘œð‘ ,ð‘£ð‘›ð‘’ð‘”)}âˆˆX ;
3 randomly sample a subset of users & items with ratio ð›¼;
4 replace initial embeddings of masked ð‘¢/ð‘£with[ð‘€ð´ð‘†ð¾];
5 inference collaborative-side representation eð‘¢/ð‘£withR;
6 calculate model optimization objective LRbased onB;
7 calculateð¿ð‘–ð‘›ð‘“ð‘œ w.r.t. Eq (17 & 18) for masked ð‘¢/ð‘£inB;
8L=LR+Lð‘–ð‘›ð‘“ð‘œ;
9 Î˜â†Î˜âˆ’ðœ‚âˆ‡Î˜L;
10until convergence ;
A SUPPLEMENTARY MATERIAL
In the supplementary materials, we provide the training procedure
of our proposed framework, RLMRec, through pseudocode. We also
offer detailed insights into the design of prompts, accompanied by
examples, to visualize the profile generation process within our
item-to-user generation paradigm. Finally, we present experiment
details for the reranking task mentioned in Section 1, where we
analyze specific examples within the task.
A.1 Pseudocode of RLMRec
This section introduces the pseudocode for our model-agnostic
RLMRec framework implementations, namely RLMRec-Con and
RLMRec-Gen. The focus is on the training procedure of these im-
plementations. Prior to training, user and item profiles are prepro-
cessed, and their semantic embeddings sare generated using text
models. Algorithm 1 presents the training procedure for RLMRec-
Con, while Algorithm 2 outlines the process for RLMRec-Gen.The difference between RLMRec-Con and RLMRec-Gen is that
RLMRec-Gen randomly masks a portion of users/items before the
base model encodes the CF-side relational representations. The
objective function Lð‘–ð‘›ð‘“ð‘œ for mutual information maximization is
then computed based on the representations of the masked users
and items. In contrast, RLMRec-Con models the density ratio in a
contrastive manner and calculates the Lð‘–ð‘›ð‘“ð‘œ objective for all users
and items in the batch data, including both positives and negatives.
A.2 Details of Profile Generation
In this section, we offer a comprehensive explanation of the gener-
ation process for both user and item profiles. Real examples from
the Amazon-book dataset are used to illustrate this process, as
depicted in Figure 7 and Figure 8. We adopt a general interaction
paradigm with large language models (LLMs), where the system
prompt serves as an instruction to guide the profile generation
task. While the Amazon-book dataset is specifically showcased,
the overall generation process remains consistent for the Yelp and
Steam datasets as well, with minor differences in the instructions
provided to represent the data information.
A.2.1 Example of the Generated Item Profile. Figure 7 show-
cases an example of item profile generation specifically for the
Amazon-book dataset. The instruction prompt provided to the lan-
guage models for all items remains consistent, directing them to
summarize the types of books that would appeal to users, thus offer-
ing valuable information for recommendation purposes. The input
information consists of the bookâ€™s title and original description
from the dataset. To maintain consistency and facilitate parsing,
we enforce the requirement that the output of the language mod-
els adhere to the JSON format. Furthermore, it is essential for the
language models to provide their reasoning behind the generated
profile, ensuring high-quality summarization while preventing any
potential hallucinations. The generated results demonstrate that the
language model, in this case ChatGPT, accurately captures from the
book description that the book is likely to attract readers interested
in mental health and womenâ€™s experiences.
A.2.2 Example of the Generated User Profile. Figure 8 illus-
trates the process of generating user profiles using the Amazon-
book dataset as an example. Our approach adopts an item-to-user
generation paradigm, which allows us to leverage the previously
generated profiles that describe the interaction preferences of items.
To accomplish this, our prompt methodology incorporates not only
usersâ€™ feedback information on items but also the profiles of the
items themselves. By utilizing both sources of information compre-
hensively, large language models are empowered to capture usersâ€™
true preferences with enhanced accuracy. In the presented example,
leveraging both the book descriptions and usersâ€™ review text, the
language models distill the userâ€™s preference for young adult fiction
that seamlessly combines paranormal or supernatural elements.
A.3 Analysis on the Reranking Task with LLMs
In this section, we explore real-world scenarios where LLMs are
employed for reranking tasks on the Amazon-book dataset, as
introduced in Section 1. Firstly, as depicted in Figure 9, we carefully
design the instruction and input prompt. We utilize the item ID as
3473

--- Page 11 ---
Representation Learning with Large Language Models for Recommendation WWW â€™24, May 13â€“17, 2024, Singapore, Singapore
You will serve as an assistant to help me summarize which types of users would enjoy a specific book . 
I will provide you with the title and a description of the book. Here are the instructions: 
1. I will provide you with information in the form of a JSON string that describes the book: 
{  "title": "the title of the book", (if there is no title, I will set this value to "None")
"description": "a description of the book", (if there is no description, I will set this value to "None") } 
Requirements: 
1. Please provide your answer in JSON format , following this structure: 
{  "summarization": "A summarization of what types of users would enjoy this book" (if you are unable to summarize it, please set this value to "None") 
"reasoning ": "briefly explain your reasoning for the summarizationâ€œ } 
2. Please ensure that the "summarization" is no longer than 200 words. 3. Please ensure that the "reasoning" is no longer than 200 words. 
4. Do not provide any other text outside the JSON string.Instruction
{  "title": "The Bell Jar: A Novel (Perennial Classics)", 
"description": "Plath was an excellent poet but is known to many for this largely autobiographical novel. The Bell Jartells the story of a gifted young 
woman's mental breakdown beginning during a summer internship as a junior editor at a magazine in New York City in the early 1950s. The real Plath 
committed suicide in 1963 and left behind this scathingly sad, honest and perfectly -written book, which remains one of the best -told tales of a woman's 
descent into insanity.--This text refers to the Hard coveredition. "}
{  "summarization": "The Bell Jar would appeal to those interested in reading about mental health and women's experiences. Specifically, readers who 
enjoy raw and honest depictions of mental illness and its effects on a young woman's life would appreciate this book.", 
"reasoning": "The Bell Jar delves into the mental breakdown of a young woman and her experiences navigating mental health and societal expectations 
as a woman in the 1950s. The book's autobiographical nature and raw, honest depiction of mental illness make it a compelling read for those interested in 
exploring these themes. Additionally, readers looking for works that examine the intersection of gender and mental illness would find The Bell Jar 
particularly thought -provoking." } Generated Item ProfileInput Prompt
Figure 7: Case study on item profile generation in Amazon-book data.
You will serve as an assistant to help me determine which types of books a specific user is likely to enjoy . 
I will provide you with information about books that the user has purchased, as well as his or her reviews of those books. 
Here are the instructions: 
1. Each purchased book will be described in JSON format, with the following attributes: {  "title": "the title of the book", (if there is no title, I will set this value to "None") 
"description ": "a description of what types of users will like this book
", 
"review": "the user's review on the book" (if there is no review , I will set this value to "None") } 
2. The information I will give you: PURCHASED ITEMS : a list of JSON strings describing the items that the user has purchased. 
Requirements: 
1. Please provide your decision in JSON format , following this structure: 
{  "summarization": "A summarization of what types of books this user is likely to enjoy" (if you are unable to summarize it, please set this value to 
"None") 
"reasoning ": "briefly explain your reasoning for the summarization" } 
2. Please ensure that the "summarization" is no longer than 100 words. 3. The "reasoning" has no word limits. 
4. Do not provided any other text outside the JSON string.
Instruction
PURCHASED ITEMS: [ {  "title": "Croak", 
"description": " Young adult readers who enjoy paranormal and fantasy themes would enjoy Croak.", 
"review": "Loved the writing style
, was different than most of what I have read. The narrative was like a storyteller, you could hear someone telling 
the story to you. â€¦"} 
{  "title": "Deadly Cool (Hartley Featherstone)", 
"description": "Teenage girls who enjoy a mix of humor, mystery, and high school drama would enjoy Deadly Cool by Gemma Halliday. With 
plenty of red herrings and a quick pace, this book will keep â€¦", 
"review": "I really enjoyed reading this , was laughing out loud in the middle of the night. ..."} 
{  "title": "Stitch (Stitch Trilogy, Book 1)", 
"description": " Fans of young adult paranormal romance novels with a dash of mystery and suspense would enjoy Stitch (Stitch Trilogy, Book 1).",
"review": â€œâ€¦. Book started out really well , had me totally hooked from the start . Love me a good ghost story, â€¦. "} 
â€¦ (Omitted due to page limit ) ] Input Prompt
{  "summarization": "This user enjoys young adult fiction that blends paranormal or supernatural elements with romance, mystery, humor, and coming -
of-age themes. They also appreciate stories with complex world -building â€¦ .", 
"reasoning": "Based on the reviews and descriptions of the purchased items, the user seems to be drawn to young adult fiction that features 
paranormal or supernatural elements, such as ghosts and magical powers. They also enjoy a mix of genres, including romance, mystery, humor, and 
coming -of-age themes. â€¦ ." }Generated User Profile
Figure 8: Case study on user profile generation in Amazon-book data.
3474

--- Page 12 ---
WWW â€™24, May 13â€“17, 2024, Singapore, Singapore Xubin Ren et al.
You serve as an assistant that helps me to recommend 20 items (each item is a book) to a specific user from a candidate item setwith the size of 40.
First, I will provide you with a list of items that he or she has already interacted with.
Then, I will provide you with a candidate item set which includes the index and title of each item.
Your goal is to create a list of recommended items from the candidate item set for the user, and the more recommended items are in the front of the list.
Here are the instructions:1. Each item in the candidate set will be described in JSON format, with the following attributes:{
"index": "a unique integer to identify the item","title": "the title of the item (book)"
}
2. The information I will give you:
INTERACTED ITEMS: a list of titles of items that the user has interacted before.CANDIDATE ITEMS: a list of JSON strings that contains the candidate items.
Requirements:
1. When recommending, please explore his/her preferences through the items that the user has interacted with to determine the recommendation list.
2. Recommended items can only be selected from the CANDIDATE ITEMS.
3. Please provide your decision in JSON format, following this structure:{
"items": "a list of index of the recommend items" (e.g., [23, 45, 68, ...])
"reasoning": "briefly explain your reasoning for the decision"
}
4. Make sure there are 20 recommended items in the list and do not use the title to represent items in the list.
5. Do not provided any other text outside the JSON string.
Instruction
{  "items": [585, 597, 330, 1098 , 293, 344, 327 , 340, 752, 1141 , 1071, 1022, 329, 319, 2911, 1057 , 1253 , 721, 974, 1127 ],
"reasoning": "Based on the user's previous interactions, it seems that they enjoy books with dark and intense themes, so I h ave selected books like 
'Raw', 'Captive in the Dark', and 'Seduced in the Dark' that fit this genre. I have also included some books with a similar w riting style like 'Thoughtless' 
and 'Slammed'. Additionally, I have chosen books from popular series such as 'Lux' and 'Divergent', which the user may be int erested in based on their 
previous interactions."} Rerank Results
INTERACTED ITEMS: ['The Sea of Tranquility: A Novel', 'Killing Sarai (In the Company of Killers)', 'Hopeless', 'The Raven Boy s (Raven Cycle)', 
'Truth (Consequences)', 'How to Kill a Rock Star', 'Unteachable', 'Shadow and Bone ( Grisha Trilogy)', 'Under Different Stars (The Kricket Series) 
(Volume 1)', 'Running in Place (Mending Hearts) (Volume 2)â€™] 
CANDIDATE ITEMS: [ â€¦ 
{"index": 329, "title": "Point of Retreat"} {"index": 207, "title": "Vain: Book One of The Seven Deadly Series (Volume 1)"} 
{"index": 269, "title": "Onyx (Lux)"} {"index": 597, "title": "Captive in the Dark: The Dark Duet"} 
{"index": 340, "title": "Sins &amp; Needles (The Artists Trilogy)"} {"index": 208, "title": "Ten Tiny Breaths"} 
{"index": 940, "title": "Angelfall (Penryn &amp; the End of Days, Book 1)"} 
â€¦ (Omitted due to page limit ) ]
Input Prompt
Figure 9: Case study on LLMs-based reranking. The candidate items are retrieved by LightGCN.
a key to index the items, along with their textual information such
as the book title. This approach aims to enhance the accuracy of
the generated outputs by avoiding direct generation of item titles
that may not precisely match the original titles.
In the prompt, we include the historical purchased books of the
user as a reference, along with a list of 40 candidate items retrieved
by LightGCN. The goal is for the LLM to select the top 20 items for
recommendation. However, upon examining the output results, it
becomes apparent that the language models have recommended
some non-existent items (highlighted in green) within the provided
list. Despite utilizing item IDs for indexing, this occurrence is com-
mon in many reranking examples, and the presence of non-existent
items can undoubtedly impact the overall reranking performance.
Additionally, the number of correctly recommended items from
the language models is lower than the retrieved items (highlightedinred). This discrepancy is primarily attributed to the limited tex-
tual information available for the language models to effectively ex-
ploit usersâ€™ preferences. Moreover, the retrieved item list, learned by
the state-of-the-art method LightGCN, benefits from collaborative
information beyond just the textual content. This collaborative in-
formation contributes to the improved performance of the retrieval
process compared to the language modelsâ€™ recommendations.
Incorporating other raw textual information from the datasets to
improve performance may have some anticipated limitations: i) The
limitation of input token numbers may constrain the size of candi-
date items, as many raw descriptions can be excessively lengthy.
ii) Raw descriptions may be missing or contain substantial noise
in certain datasets. The absence of descriptions or the presence of
noisy information can hinder the language modelsâ€™ comprehen-
sion of usersâ€™ preferences. iii) Including a larger amount of input
data, such as additional raw textual information, can increase the
computational cost, which impacts the systemâ€™s scalability.
3475

